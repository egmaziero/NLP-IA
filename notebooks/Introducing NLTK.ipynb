{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "Its a platform with a lot of modules to work with natural language. It provides tokenization, stemming, tagging, parsing and semantic analysis.\n",
    "\n",
    "Run the command bellow and download the following data:\n",
    "\n",
    "**In Corpora**\n",
    "- mac_morpho\n",
    "\n",
    "- floresta\n",
    "\n",
    "- stopwords\n",
    "\n",
    "**In Models**\n",
    "- punkt\n",
    "\n",
    "- rslp\n",
    "\n",
    "The files will be downloaded to user home folder inside *nltk_data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "## sentence & word segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoje está um ótimo dia para estudar NLP com python 3.*!\n",
      "['Hoje', 'está', 'um', 'ótimo', 'dia', 'para', 'estudar', 'NLP', 'com', 'python', '3', '.', '*', '!']\n",
      "Explore o NLTK, que tem rotinas para tratar a linguagem natural.\n",
      "['Explore', 'o', 'NLTK', ',', 'que', 'tem', 'rotinas', 'para', 'tratar', 'a', 'linguagem', 'natural', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hoje está um ótimo dia para estudar NLP com python 3.*! Explore o NLTK, que tem rotinas para tratar a linguagem natural.\"\n",
    "sentences =nltk.tokenize.sent_tokenize(text, language='portuguese')\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    tokens = nltk.word_tokenize(sentence, language='portuguese')\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "## keeping word stem (*tronco*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cant\n",
      "cant\n",
      "camput\n",
      "['O', 'canto', 'é', 'retângulo', '!']\n",
      "['o', 'cant', 'é', 'retângul', '!']\n"
     ]
    }
   ],
   "source": [
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "print(stemmer.stem(\"canto\"))\n",
    "print(stemmer.stem(\"cantar\"))\n",
    "print(stemmer.stem(\"camputador\"))\n",
    "\n",
    "sent = \"O canto é retângulo!\"\n",
    "tokens = nltk.word_tokenize(sent, language='portuguese')\n",
    "print(tokens)\n",
    "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "print(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords\n",
    "## keeping content words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ônibus parou centro campo futebol\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "sent = \"O ônibus parou no centro do campo de futebol\"\n",
    "print(\" \".join([token for token in sent.lower().split() if token not in stopwords]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging\n",
    "## morphosyntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jersei', 'atinge', 'média', 'de', 'Cr$', '1,4', ...]\n",
      "[['Jersei', 'atinge', 'média', 'de', 'Cr$', '1,4', 'milhão', 'em', 'a', 'venda', 'de', 'a', 'Pinhal', 'em', 'São', 'Paulo'], ['Programe', 'sua', 'viagem', 'a', 'a', 'Exposição', 'Nacional', 'do', 'Zebu', ',', 'que', 'começa', 'dia', '25'], ...]\n",
      "[[('Jersei', 'N'), ('atinge', 'V'), ('média', 'N'), ('de', 'PREP'), ('Cr$', 'CUR'), ('1,4', 'NUM'), ('milhão', 'N'), ('em', 'PREP|+'), ('a', 'ART'), ('venda', 'N'), ('de', 'PREP|+'), ('a', 'ART'), ('Pinhal', 'NPROP'), ('em', 'PREP'), ('São', 'NPROP'), ('Paulo', 'NPROP')], [('Programe', 'V'), ('sua', 'PROADJ'), ('viagem', 'N'), ('a', 'PREP|+'), ('a', 'ART'), ('Exposição', 'NPROP'), ('Nacional', 'NPROP'), ('do', 'NPROP'), ('Zebu', 'NPROP'), (',', ','), ('que', 'PRO-KS-REL'), ('começa', 'V'), ('dia', 'N'), ('25', 'N|AP')], ...]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import mac_morpho\n",
    "print(mac_morpho.words())\n",
    "print(mac_morpho.sents())\n",
    "print(mac_morpho.tagged_sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training a tagger\n",
    "### unigram based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696285344352381\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences = mac_morpho.tagged_sents()\n",
    "unigram_tagger = nltk.UnigramTagger(tagged_sentences)\n",
    "print(unigram_tagger.evaluate(tagged_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('O', 'ART'), ('canto', 'N'), ('é', 'V'), ('retângulo', None), ('!', '!')]\n",
      "[('Eu', 'PROPESS'), ('canto', 'N'), ('pra', 'PREP'), ('você', 'PROPESS'), ('!', '!')]\n"
     ]
    }
   ],
   "source": [
    "sent = \"O canto é retângulo!\"\n",
    "tokens = nltk.word_tokenize(sent, language='portuguese')\n",
    "print(unigram_tagger.tag(tokens))\n",
    "sent = \"Eu canto pra você!\"\n",
    "tokens = nltk.word_tokenize(sent, language='portuguese')\n",
    "print(unigram_tagger.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigram based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8958614471474539\n"
     ]
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(tagged_sentences, backoff=unigram_tagger)\n",
    "print(bigram_tagger.evaluate(tagged_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('O', 'ART'), ('canto', 'N'), ('é', 'V'), ('retângulo', None), ('!', '!')]\n",
      "[('Eu', 'PROPESS'), ('canto', 'N'), ('pra', 'PREP'), ('você', 'PROPESS'), ('!', '!')]\n"
     ]
    }
   ],
   "source": [
    "sent = \"O canto é retângulo!\"\n",
    "tokens = nltk.word_tokenize(sent, language='portuguese')\n",
    "print(bigram_tagger.tag(tokens))\n",
    "sent = \"Eu canto pra você!\"\n",
    "tokens = nltk.word_tokenize(sent, language='portuguese')\n",
    "print(bigram_tagger.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigram based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904358193138164\n"
     ]
    }
   ],
   "source": [
    "trigram_tagger = nltk.TrigramTagger(tagged_sentences, backoff=bigram_tagger)\n",
    "print(trigram_tagger.evaluate(tagged_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('O', 'ART'), ('canto', 'N'), ('é', 'V'), ('retângulo', None), ('!', '!')]\n",
      "[('Eu', 'PROPESS'), ('canto', 'N'), ('pra', 'PREP'), ('você', 'PROPESS'), ('!', '!')]\n",
      "[('Eu', 'PROPESS'), ('compro', 'V'), ('pra', 'PREP'), ('você', 'PROPESS'), ('!', '!')]\n"
     ]
    }
   ],
   "source": [
    "sent = \"O canto é retângulo!\"\n",
    "tokens = nltk.word_tokenize(sent, language='portuguese')\n",
    "print(trigram_tagger.tag(tokens))\n",
    "sent = \"Eu canto pra você!\"\n",
    "tokens = nltk.word_tokenize(sent, language='portuguese')\n",
    "print(trigram_tagger.tag(tokens))\n",
    "sent = \"Eu compro pra você!\"\n",
    "tokens = nltk.word_tokenize(sent, language='portuguese')\n",
    "print(trigram_tagger.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "## Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Um', 'revivalismo', 'refrescante', 'O', '7_e_Meio', ...]\n",
      "[['Um', 'revivalismo', 'refrescante'], ['O', '7_e_Meio', 'é', 'um', 'ex-libris', 'de', 'a', 'noite', 'algarvia', '.'], ...]\n",
      "[[('Um', '>N+art'), ('revivalismo', 'H+n'), ('refrescante', 'N<+adj')], [('O', '>N+art'), ('7_e_Meio', 'H+prop'), ('é', 'P+v-fin'), ('um', '>N+art'), ('ex-libris', 'H+n'), ('de', 'H+prp'), ('a', '>N+art'), ('noite', 'H+n'), ('algarvia', 'N<+adj'), ('.', '.')], ...]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import floresta\n",
    "print(floresta.words())\n",
    "print(floresta.sents())\n",
    "print(floresta.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
